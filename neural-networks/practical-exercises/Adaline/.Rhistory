minseq <- 0
maxseq <- 6
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
s1 <- 0.4
s2 <- 0.4
##############################################
# Gerando dados amostrados das distribuições #
# m1=(2,2)', m2=(4,4)' #
xc1 <- matrix(rnorm(N*2),ncol=2)*s1+t(matrix((c(2,2)),ncol=N,nrow=2))
xc2 <- matrix(rnorm(N*2),ncol=2)*s2+t(matrix((c(4,4)),ncol=N,nrow=2))
xin <- rbind(xc1,xc2)
##############################################
# Rótulos das entradas #
yd <- rbind(matrix(0, nrow=N, ncol=1), matrix(1, nrow=N, ncol=1))
##############################################
# Plot dos dados #
plot(xc1[,1], xc1[,2], col='red', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq), xlab='x_1', ylab='x_2',
sub = 'Dados amostrados')
par(new=T)
plot(xc2[,1], xc2[,2], col='blue', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq), xlab='', ylab='')
# Chunk 3
##############################################
# Treinamento #
train <- list()
train <- trainperceptron(xin,yd,eta,tol,maxepocas,par)
# Vetor de pesos #
w <- train$wt
paste(w)
# Chunk 4
##############################################
# Mapeamento do grid  #
seqi <- seq(minseq,maxseq,0.1)
seqj <- seq(minseq,maxseq,0.1)
M <- matrix(1,nrow =length(seqi),ncol=length(seqj))
# Percorrer o espaço e gerar a saída #
ci <- 0
for (i in seqi)
{
ci <- ci+1
cj <- 0
for (j in seqj)
{
cj <- cj + 1
xt <- c(i,j)
M[ci,cj] <- yperceptron(t(xt),w,1)
}
}
# Chunk 5
##############################################
# Resposta em R2 #
plot(xc1[,1], xc1[,2], col='red', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='x_1',ylab='x_2',
sub = 'Resposta do Perceptron Simples')
par(new=T)
plot(xc2[,1], xc2[,2], col='blue', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='',ylab='')
par(new=T)
contour(seqi,seqj,M,xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='',ylab='')
w
w
# Chunk 1
rm(list=ls())
library('plot3D')
##############################################
# Cálculo da resposta do neurônio #
# (função degrau) #
yperceptron <- function(xvec, w, par)
{
if(par == 1)
xvec <- cbind(-1, xvec)
u <- xvec %*% w
y <- 1*(u >= 0)
return(as.matrix(y))
}
##############################################
# Treinamento de um Perceptron simples #
# (ajuste do vetor de pesos) #
trainperceptron <- function(xin, yd, eta, tol, maxepocas, par)
{
dimxin <- dim(xin)
N <- dimxin[1]
n <- dimxin[2]
if(par == 1)
{
wt <- as.matrix(runif(n+1) - 0.5)
xin <- cbind(-1, xin)
}
else
{
wt <- as.matrix(runif(n) - 0.5)
}
nepocas <- 0
eepoca <- tol+1
evec <- matrix(nrow=1, ncol=maxepocas)
while ((nepocas < maxepocas) && (eepoca > tol))
{
ei2 <- 0
xseq <- sample(N)
for(i in 1:N)
{
irand <- xseq[i]
yhati <- as.double((xin[irand,] %*% wt) >= 0)
ei <- yd[irand]- yhati
dw <- eta*ei*xin[irand,]
wt <- wt+dw
ei2 <- ei2+ei*ei
}
nepocas <- nepocas+1
evec[nepocas] <- ei2/N
eepoca <- evec[nepocas]
}
retlist <- list(wt=wt, evec=evec[1:nepocas])
return(retlist)
}
# Chunk 2
##############################################
# Parâmetros #
N <- 200
minseq <- 0
maxseq <- 6
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
s1 <- 0.4
s2 <- 0.4
##############################################
# Gerando dados amostrados das distribuições #
# m1=(2,2)', m2=(4,4)' #
xc1 <- matrix(rnorm(N*2),ncol=2)*s1+t(matrix((c(2,2)),ncol=N,nrow=2))
xc2 <- matrix(rnorm(N*2),ncol=2)*s2+t(matrix((c(4,4)),ncol=N,nrow=2))
xin <- rbind(xc1,xc2)
##############################################
# Rótulos das entradas #
yd <- rbind(matrix(0, nrow=N, ncol=1), matrix(1, nrow=N, ncol=1))
##############################################
# Plot dos dados #
plot(xc1[,1], xc1[,2], col='red', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq), xlab='x_1', ylab='x_2',
sub = 'Dados amostrados')
par(new=T)
plot(xc2[,1], xc2[,2], col='blue', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq), xlab='', ylab='')
# Chunk 3
##############################################
# Treinamento #
train <- list()
train <- trainperceptron(xin,yd,eta,tol,maxepocas,par)
# Vetor de pesos #
w <- train$wt
paste(w)
# Chunk 4
##############################################
# Mapeamento do grid  #
seqi <- seq(minseq,maxseq,0.1)
seqj <- seq(minseq,maxseq,0.1)
M <- matrix(1,nrow =length(seqi),ncol=length(seqj))
# Percorrer o espaço e gerar a saída #
ci <- 0
for (i in seqi)
{
ci <- ci+1
cj <- 0
for (j in seqj)
{
cj <- cj + 1
xt <- c(i,j)
M[ci,cj] <- yperceptron(t(xt),w,1)
}
}
# Chunk 5
##############################################
# Resposta em R2 #
plot(xc1[,1], xc1[,2], col='red', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='x_1',ylab='x_2',
sub = 'Resposta do Perceptron Simples')
par(new=T)
plot(xc2[,1], xc2[,2], col='blue', type='p', xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='',ylab='')
par(new=T)
contour(seqi,seqj,M,xlim=c(minseq,maxseq),
ylim=c(minseq,maxseq),xlab='',ylab='')
w
library(mlbench)
data("BreastCancer")
summary(BreastCancer)
dim(BreastCancer)
X <- BreastCancer[,2:10]
X[is.na(X)]<-0
X[is.na(X)] <- 0
X
X <- BreastCancer[,2:10]
clear
summary(X)
is.na(X)
count(is.na(X))
sum(is.na(X))
X <- as.matrix(BreastCancer[,2:10])
X[is.na(X)] <- 0
Y <- as.matrix(as.numeric(BreastCancer[,11]))
density(X, kernel = 'gaussian')
density(X[,1], kernel = 'gaussian')
X
X <- as.numeric(X)
X
X <- as.matrix(as.numeric(X))
X
X <- as.matrix(as.numeric(BreastCancer[,2:10]))
X <- as.numeric(as.matrix(BreastCancer[,2:10]))
X
dim(X)
X <- BreastCancer[,2:10]
X
X[X=="<NA>"]
X[X=="<NA>"] <- 0
X
density(X, kernel = 'gaussian')
density(X[-1,], kernel = 'gaussian')
density(X[-1,2], kernel = 'gaussian')
setwd("~/Dropbox/Study/UFMG/Classes/ELT075/Prática/Adaline")
# Chunk 1
rm(list=ls())
library('plot3D')
source('yadaline.R')
source('trainadaline.R')
# Parâmetros #
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
ptrain <- 0.7
ptest <- 1 - ptrain
# Chunk 2
##########################################
# Exercício 1 #
ex1_x <- as.matrix(read.table('Ex1_x'))
ex1_y <- as.matrix(read.table('Ex1_y'))
ex1_t <- as.matrix(read.table('Ex1_t'))
# Amostragem: treino e teste #
index <- sample(2, nrow(ex1_x), replace=TRUE, prob=c(ptrain,ptest))
# Treino #
xtrain <- as.matrix(ex1_x[which(index==1),])
ytrain <- as.matrix(ex1_y[which(index==1)])
ttrain <- as.matrix(ex1_t[which(index==1)])
# Teste #
xtest <- as.matrix(ex1_x[which(index==2),])
ytest <- as.matrix(ex1_y[which(index==2)])
ttest <- as.matrix(ex1_t[which(index==2)])
# Treinamento #
train <- trainadaline(xtrain, ytrain, eta, tol, maxepocas, par)
wt <- train$wt
# Teste #
test <- yadaline(xtest, wt, par)
# MSE #
mse <- sum((ytest - test)^2)/(length(ytest))
# Chunk 3
# Plot: treinamento #
plot(ex1_t,ex1_x,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),xlab='t',ylab='',col='red')
par(new=T)
plot(ttrain, xtrain, type='p', pch=19, col='red',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ttrain, ytrain, type='p', pch=19, col='blue',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para treinamento")
legend(0.2, -0.4, legend=c("Entrada", "Saída Original"),
col=c("red", "blue"), lty=1:2, cex=0.8)
# Chunk 4
# Plot: Teste #
plot(ex1_t,ex1_x*wt[2]+wt[1],type='o',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',col='green',xlab='')
par(new=T)
plot(ttest, ytest, type='p', pch=19, col='green',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para teste")
legend(0.2, -0.4, legend=c("Saída Prevista", "Saída Original"),
col=c("blue", "green"), lty=1:3, cex=0.8)
# Chunk 5
# Parâmetros do modelo#
sprintf("a = %1$.3f, b = %2$.3f", wt[2], wt[1])
# MSE #
sprintf("MSE = %.3f%%", 100*mse)
# Chunk 6
rm(list=ls())
library('plot3D')
source('yadaline.R')
source('trainadaline.R')
# Parâmetros #
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
ptrain <- 0.7
ptest <- 1 - ptrain
# Chunk 7
##########################################
# Exercício 2 #
x <- as.matrix(read.table('x'))
y <- as.matrix(read.table('y'))
t <- as.matrix(read.table('t'))
# Amostragem: treino e teste #
index <- sample(2, nrow(x), replace=TRUE, prob=c(ptrain,ptest))
# Treino #
xtrain <- as.matrix(x[which(index==1),])
ytrain <- as.matrix(y[which(index==1)])
ttrain <- as.matrix(t[which(index==1)])
# Teste #
xtest <- as.matrix(x[which(index==2),])
ytest <- as.matrix(y[which(index==2)])
ttest <- as.matrix(t[which(index==2)])
# Treinamento #
wt <- c()
train <- trainadaline(xtrain, ytrain, eta, tol, maxepocas, par)
wt <- train$wt
# Teste #
test <- yadaline(xtest, wt, par)
# MSE #
mse <- sum((ytest - test)^2)/(length(ytest))
# Chunk 8
# Plot #
cores <- rainbow(dim(x)[2])
for(i in 1:(dim(x)[2]-1))
{
plot(t,x[,i],type='o',pch=21, ylab='x',xlim=c(0.1*pi,2*pi),
col=cores[i],  ylim=c(min(x),max(x)),
sub="Sinais de entrada")
par(new=T)
}
i <- i + 1
plot(t,x[,i],type='o',pch=21, ylab='x',xlim=c(0.1*pi,2*pi),
col=cores[i],  ylim=c(min(x),max(x)),
sub="Sinais de entrada")
# Chunk 9
plot(t,y,type='o', col='orange',
xlim=c(min(t),max(t)),
ylim=c(min(y), max(y)), ylab='y',xlab='t')
par(new=T)
plot(ttrain, ytrain, type='p', pch=19, col='orange',
xlim=c(min(t),max(t)),
ylim=c(min(y), max(y)), ylab = '',xlab='',sub="Saída original")
# Chunk 10
plot(t,(x[,1]*wt[2]+x[,2]*wt[3]+x[,3]*wt[4]+wt[1]),
type='o',xlim=c(0.1*pi,2*pi),
ylim=c(min(y),max(y)),ylab='',col='black')
par(new=T)
plot(t,y,type='o', col='orange', xlim=c(min(t),max(t)),
ylim=c(min(y), max(y)), ylab='y',xlab='t')
par(new=T)
plot(ttest, ytest, type='p', pch=19, col='orange',
xlim=c(min(t),max(t)), ylim=c(min(y), max(y)),
ylab = '',xlab='',sub="Saída prevista")
legend(0.2, 8, legend=c("Original", "Previsto"),
col=c("orange", "black"), lty=1:2, cex=0.8)
# Chunk 11
# Parâmetros do modelo #
sprintf("a = %1$.3f, b = %2$.3f, c = %3$.3f, d = %4$.3f",
wt[1], wt[2], wt[3], wt[4])
# MSE #
sprintf("MSE = %.3f%%", 100*mse)
# Chunk 1
rm(list=ls())
library('plot3D')
source('yadaline.R')
source('trainadaline.R')
# Parâmetros #
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
ptrain <- 0.7
ptest <- 1 - ptrain
# Chunk 2
##########################################
# Exercício 1 #
ex1_x <- as.matrix(read.table('Ex1_x'))
ex1_y <- as.matrix(read.table('Ex1_y'))
ex1_t <- as.matrix(read.table('Ex1_t'))
# Amostragem: treino e teste #
index <- sample(2, nrow(ex1_x), replace=TRUE, prob=c(ptrain,ptest))
# Treino #
xtrain <- as.matrix(ex1_x[which(index==1),])
ytrain <- as.matrix(ex1_y[which(index==1)])
ttrain <- as.matrix(ex1_t[which(index==1)])
# Teste #
xtest <- as.matrix(ex1_x[which(index==2),])
ytest <- as.matrix(ex1_y[which(index==2)])
ttest <- as.matrix(ex1_t[which(index==2)])
# Treinamento #
train <- trainadaline(xtrain, ytrain, eta, tol, maxepocas, par)
wt <- train$wt
# Teste #
test <- yadaline(xtest, wt, par)
# MSE #
mse <- sum((ytest - test)^2)/(length(ytest))
# Chunk 3
# Plot: treinamento #
plot(ex1_t,ex1_x,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),xlab='t',ylab='',col='red')
par(new=T)
plot(ttrain, xtrain, type='p', pch=19, col='red',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ttrain, ytrain, type='p', pch=19, col='blue',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para treinamento")
legend(0.2, -0.4, legend=c("Entrada", "Saída Original"),
col=c("red", "blue"), lty=1:2, cex=0.8)
# Chunk 4
# Plot: Teste #
plot(ex1_t,ex1_x*wt[2]+wt[1],type='o',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',col='green',xlab='')
par(new=T)
plot(ttest, ytest, type='p', pch=19, col='green',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para teste")
legend(0.2, -0.4, legend=c("Saída Prevista", "Saída Original"),
col=c("blue", "green"), lty=1:3, cex=0.8)
# Chunk 1
rm(list=ls())
library('plot3D')
source('yadaline.R')
source('trainadaline.R')
# Parâmetros #
eta <- 0.1
tol <- 0.01
maxepocas <- 10000
par <- 1
ptrain <- 0.7
ptest <- 1 - ptrain
# Chunk 2
##########################################
# Exercício 1 #
ex1_x <- as.matrix(read.table('Ex1_x'))
ex1_y <- as.matrix(read.table('Ex1_y'))
ex1_t <- as.matrix(read.table('Ex1_t'))
# Amostragem: treino e teste #
index <- sample(2, nrow(ex1_x), replace=TRUE, prob=c(ptrain,ptest))
# Treino #
xtrain <- as.matrix(ex1_x[which(index==1),])
ytrain <- as.matrix(ex1_y[which(index==1)])
ttrain <- as.matrix(ex1_t[which(index==1)])
# Teste #
xtest <- as.matrix(ex1_x[which(index==2),])
ytest <- as.matrix(ex1_y[which(index==2)])
ttest <- as.matrix(ex1_t[which(index==2)])
# Treinamento #
train <- trainadaline(xtrain, ytrain, eta, tol, maxepocas, par)
wt <- train$wt
# Teste #
test <- yadaline(xtest, wt, par)
# MSE #
mse <- sum((ytest - test)^2)/(length(ytest))
# Chunk 3
# Plot: treinamento #
plot(ex1_t,ex1_x,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),xlab='t',ylab='',col='red')
par(new=T)
plot(ttrain, xtrain, type='p', pch=19, col='red',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ttrain, ytrain, type='p', pch=19, col='blue',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para treinamento")
legend(0.2, -0.4, legend=c("Entrada", "Saída Original"),
col=c("red", "blue"), lty=1:2, cex=0.8)
# Chunk 4
# Plot: Teste #
plot(ex1_t,ex1_x*wt[2]+wt[1],type='o',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',xlab='',col='blue')
par(new=T)
plot(ex1_t,ex1_y,type='o',xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x),max(ex1_x)),ylab='',col='green',xlab='')
par(new=T)
plot(ttest, ytest, type='p', pch=19, col='green',
xlim=c(min(ex1_t),max(ex1_t)),
ylim=c(min(ex1_x), max(ex1_x)), ylab = '',xlab='',
sub="Amostras preenchidas foram usadas para teste")
legend(0.2, -0.4, legend=c("Saída Prevista", "Saída Original"),
col=c("blue", "green"), lty=1:3, cex=0.8)
