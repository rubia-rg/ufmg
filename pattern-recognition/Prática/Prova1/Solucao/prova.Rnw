\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}

\title{Avaliação de Reconhecimento de Padrões}
\author{Rúbia Reis Guerra \\ 2013031143}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

\section{Pacotes utilizados}
<<echo=T,fig=F>>=
rm(list=ls())
library('mclust')

###########################
# Auxiliares #
tp <- c()
fp <- c()
fn <- c()
prec <- c()
rec <- c()
f1 <- c()
error <- c()
mse <- c()
sde <- c()
@

\section{Análise dos dados}
<<echo=T,fig=T>>=
bupa <- as.matrix(read.csv("bupa.data", header=FALSE))
X <- bupa[,(1:6)] # dados de entrada
Y <- as.matrix(2*(bupa[,7]-1.5)) # rotulos das classes como [-1,+1]
i_cm1 <- which(Y == -1) # amostras da classe -1
i_c1 <- which(Y == 1) # amostras da classe +1
Nm1 <- length(i_cm1) # tamanho da classe -1
N1 <- length(i_c1) # tamanho da classe +1

## Analise dos dados
clPairs(bupa, Y) ## Analise 
cor(bupa) ## Calculo da correlacao

@

Como pode ser observado no plot gerado, existe um alto grau de correlação entre as variáveis de entrada e, como consequência, ocorre a sobreposição das classes. Podemos assumir que se trata de um problema multi-modal com características de separacão não-lineares e tentar resolvê-lo por um modelo de misturas normais.

\section{Coerência da rotulação}
Para analisar a coerência entre os agrupamentos gerados pelo método de clustering e os rótulos de cada classe, utilizou-se o pacote \textit{mclust} e, em sequência, foi obtida a distribuição dos padrões da classes dentro dos agrupamentos.
<<echo=T,fig=T>>=
mod = Mclust(X) # Clustering
table(mod$classification, Y) # Clusters x Classes
plot(mod, what = "classification") # Visualização dos agrupamentos
@

Observamos que não há relação direta entre os rótulos das classes e os agrupamentos obtidos pelo algoritmo Kmédias. Os padrões foram distribuídos entre os 4 agrupamentos de forma que não necessariamente exemplos de uma mesma classe pertencem ao mesmo cluster. Esta observação é coerente, pois como analisado no item anterior, a correlação entre os atributos de entrada é significativa e as classes se sobrepõem espacialmente.

\section{Classificação}
O problema de classificação foi tratado utilizando-se um classificador Bayesiano. As probabilidades a priori foram calculadas a partir da quantidade de amostras de cada classe e as densidades de probabilidade foram encontradas utilizando-se um modelo de mistura de gaussianas, obtido pelo algoritmo K-médias.
<<echo=T,fig=F>>=
for(j in 1:10){
  ###########################
  # Partição entre treino e teste #
  index <- sample(2, nrow(bupa), replace=TRUE, prob=c(0.70,0.30))
  
  ###########################
  # Conjunto de treinamento #
  training <- X[which(index==1),]
  trainingLabels <- as.matrix(Y[which(index==1)])
  
  ###########################
  # Conjunto de teste #
  test <- X[which(index==2),]
  testLabels <- as.matrix(Y[which(index==2)])
  
  ###########################
  # Probabilidades a priori #
  pc1 <- Nm1/(Nm1+N1)
  pc2 <- N1/(Nm1+N1)
  
  ###########################
  # Treinamento #
  mod1 = densityMclust(training[which(trainingLabels==(-1)),])
  mod2 = densityMclust(training[which(trainingLabels==1),])
  
  ###########################
  # Teste #
  pxc1 <- dens(modelName=mod1$modelName, data = test, parameters = mod1$parameters)
  pxc2 <- dens(modelName=mod2$modelName, data = test, parameters = mod2$parameters)
  
  ###########################
  # Classificação #
  Ntest <- dim(test)[1]
  testY <- c()
  for(i in 1:Ntest)
  {
    testY[i] <- ifelse(pxc1[i]/pxc2[i] >= pc2/pc1, -1, 1)
    error[i] <- (testY[i]-testLabels[i])^2
  }
  
  # MSE e SD #
  mse[j] <- mean(error)
  sde[j] <- sd(error)
  
  # Matriz de confusão #
  testCM <- table(testY,testLabels)
  
  # Precision, recall, F1 #
  tp[j] <- sum((testY==(-1)) & (testLabels==(-1))) # True positives
  fp[j] <- sum((testY==(-1)) & (testLabels==1)) # False positives
  fn[j] <- sum((testY==1) & (testLabels==(-1))) # False negatives
  prec[j] <- tp[j]/(tp[j] + fp[j]) # Precision
  rec[j] <- tp[j]/(tp[j] + fn[j]) # Recall
  f1[j] <- 2*prec[j]*rec[j]/(prec[j]+rec[j]) # F1 Score
}

mean(mse) # MSE
mean(sde) # SD
@
Analisando o desempenho do classificador após 10 iterações, conclui-se que a Regra de Bayes separa as duas classes de forma coerente.

\end{document}