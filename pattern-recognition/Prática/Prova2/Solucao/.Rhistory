plot(projX[which(Y==1),4],projX[which(Y==1),5],type='p',xlim=c(min(projX[,4]),max(projX[,4])),ylim=c(min(projX[,5]),max(projX[,5])),col='red',
xlab='PCA4',ylab='PCA5',
sub='Projeção das classes em PCA4 e PCA5')
meanx <- colMeans(X)
Xrep <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(Xrep)
us <- pcaX$rotation
projX <- Xrep %*% us
barplot(pcaX$sdev)
pcaX$sdev
meanx <- colMeans(X)
Xrep <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(Xrep)
us <- pcaX$rotation
projX <- Xrep %*% us
barplot(pcaX$sdev)
pcaX$sdev
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
pcaX$sdev
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
pcaX$sdev
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
pcaX$sdev
meanx <- colMeans(X)
Xrep <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(Xrep)
us <- pcaX$rotation
projX <- Xrep %*% us
barplot(pcaX$sdev)
pcaX$sdev
pcaX
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
bupa <- as.matrix(read.csv("bupa.data", header=FALSE))
X <- bupa[,(1:6)] # dados de entrada
Y <- as.matrix(2*(bupa[,7]-1.5)) # rotulos das classes como [-1,+1]
i_cm1 <- which(Y == -1) # amostras da classe -1
i_c1 <- which(Y == 1) # amostras da classe +1
Nm1 <- length(i_cm1) # tamanho da classe -1
N1 <- length(i_c1) # tamanho da classe +1
## Plot por pares
clPairs(bupa, Y)
meanx <- colMeans(X)
Xrep <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(Xrep)
us <- pcaX$rotation
projX <- Xrep %*% us
barplot(pcaX$sdev)
pcaX$sdev
pcaX
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
bupa <- as.matrix(read.csv("bupa.data", header=FALSE))
X <- bupa[,(1:6)] # dados de entrada
Y <- as.matrix(2*(bupa[,7]-1.5)) # rotulos das classes como [-1,+1]
i_cm1 <- which(Y == -1) # amostras da classe -1
i_c1 <- which(Y == 1) # amostras da classe +1
Nm1 <- length(i_cm1) # tamanho da classe -1
N1 <- length(i_c1) # tamanho da classe +1
## Plot por pares
clPairs(bupa, Y)
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
pcaX$sdev
pcaX
summary(pcaX)
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
summary(pcaX)
classes <- unique(Y)
class1 <- X[Y == classes[1],]
class2 <- X[Y == classes[2],]
f.score <- matrix(0, ncol = 1, nrow = ncol(X))
for(col.atributo in seq(1:ncol(X))){
atributoGlobal <- X[,col.atributo]
atributoC1 <- class1[,col.atributo]
atributoC2 <- class2[,col.atributo]
f.score[col.atributo] <- ((mean(atributoC1) - mean(atributoGlobal))^2 +
(mean(atributoC2) - mean(atributoGlobal))^2) /
(var(atributoC1) + var(atributoC2))
}
# F-SCORES
print(f.score)
features.maior.variancia <- order(f.score)
nomesColunas <- colnames(X)
print("Características que apresentam a maior variância da base")
print(nomesColunas[features.maior.variancia])
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
###########################
# F-Score #
fscore <- function(X,c1,c2,n){
f <- c()
for(i in 1:n)
{
f[i] <- ((mean(c1[,i]) - mean(X[,i]))^2
+(mean(c2[,i]) - mean(X[,i]))^2)/(sd(c1[,i])^2+sd(c2[,i])^2)
}
return(f)
}
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
###########################
# F-Score #
fscore <- function(X,c1,c2,n){
f <- c()
for(i in 1:n)
{
f[i] <- ((mean(c1[,i]) - mean(X[,i]))^2
+(mean(c2[,i]) - mean(X[,i]))^2)/(sd(c1[,i])^2+sd(c2[,i])^2)
}
return(f)
}
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
###########################
# F-Score #
fscore <- function(X,c1,c2,n){
f <- c()
for(i in 1:n)
{
f[i] <- ((mean(c1[,i]) - mean(X[,i]))^2
+(mean(c2[,i]) - mean(X[,i]))^2)/(sd(c1[,i])^2+sd(c2[,i])^2)
}
return(f)
}
bupa <- as.matrix(read.csv("bupa.data", header=FALSE))
X <- bupa[,(1:6)] # dados de entrada
Y <- as.matrix(2*(bupa[,7]-1.5)) # rotulos das classes como [-1,+1]
i_cm1 <- which(Y == -1) # amostras da classe -1
i_c1 <- which(Y == 1) # amostras da classe +1
Nm1 <- length(i_cm1) # tamanho da classe -1
N1 <- length(i_c1) # tamanho da classe +1
## Plot por pares
clPairs(bupa, Y)
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
summary(pcaX)
# Reduzindo para os dois primeiros eixos
plot(projX[,1],projX[,2],type='p',xlim=c(min(projX[,1]),max(projX[,1])),ylim=c(min(projX[,2]),max(projX[,2])),xlab='PCA1',ylab='PCA2',col='blue')
par(new=TRUE)
plot(projX[which(Y==1),1],projX[which(Y==1),2],type='p',xlim=c(min(projX[,1]),max(projX[,1])),ylim=c(min(projX[,2]),max(projX[,2])),
col='red',xlab='PCA1',ylab='PCA2',
sub='Projeção das classes em PCA1 e PCA2')
# Comparacao: reduzindo aos eixos 4 e 5
plot(projX[,4],projX[,5],type='p',xlim=c(min(projX[,4]),max(projX[,4])),ylim=c(min(projX[,5]),max(projX[,5])),xlab='PCA4',ylab='PCA5',col='blue')
par(new=TRUE)
plot(projX[which(Y==1),4],projX[which(Y==1),5],type='p',xlim=c(min(projX[,4]),max(projX[,4])),ylim=c(min(projX[,5]),max(projX[,5])),col='red',
xlab='PCA4',ylab='PCA5',
sub='Projeção das classes em PCA4 e PCA5')
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
# F-SCORES
print(f.score)
features.maior.variancia <- order(f.score)
nomesColunas <- colnames(X)
print("Características que apresentam a maior variância da base")
print(nomesColunas[features.maior.variancia])
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
print(f)
features.maior.variancia <- order(f)
nomesColunas <- colnames(X)
print("Características que apresentam a maior variância da base")
print(nomesColunas[features.maior.variancia])
f
nomesColunas <- colnames(X[,order(f)])
colnames(X[,order(f)])
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
print(f)
print("Características que apresentam a maior variância da base")
colnames(X[,order(f)])
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
print(f)
# Atributos que concentram maior variancia da base
colnames(X[,order(f)])
meanx <- colMeans(X)
X <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(X)
us <- pcaX$rotation
projX <- X %*% us
barplot(pcaX$sdev)
summary(pcaX)
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
print(f)
# Atributos que concentram maior variancia da base
colnames(X[,order(f)])
###########################
# Kmeans #
k <- list()
for(i in 1:(nrow(t(X))-1))
{
h <- kmeans(t(X),i)
k[[i]] <- h$cluster
}
k
###########################
# Hierarchical clustering #
clusters <- hclust(dist(t(X)))
plot(clusters)
###########################
# Kmeans #
k <- list()
for(i in 1:(nrow(t(X))-1))
{
h <- kmeans(t(X),i)
k[[i]] <- h$cluster
}
k
###########################
# Kmeans #
k <- list()
for(i in 1:(nrow(t(X))-1))
{
h <- kmeans(t(X),i)
k[[i]] <- h$cluster
}
k
rm(list=ls())
library('MASS')
library('mlbench')
library('mclust')
library('stats')
library('kernlab')
library('caret')
###########################
# F-Score #
fscore <- function(X,c1,c2,n){
f <- c()
for(i in 1:n)
{
f[i] <- ((mean(c1[,i]) - mean(X[,i]))^2
+(mean(c2[,i]) - mean(X[,i]))^2)/(sd(c1[,i])^2+sd(c2[,i])^2)
}
return(f)
}
bupa <- as.matrix(read.csv("bupa.data", header=FALSE))
X <- bupa[,(1:6)] # dados de entrada
Y <- as.matrix(2*(bupa[,7]-1.5)) # rotulos das classes como [-1,+1]
i_cm1 <- which(Y == -1) # amostras da classe -1
i_c1 <- which(Y == 1) # amostras da classe +1
Nm1 <- length(i_cm1) # tamanho da classe -1
N1 <- length(i_c1) # tamanho da classe +1
## Plot por pares
clPairs(bupa, Y)
meanx <- colMeans(X)
Xrep <- X - t(replicate(dim(X)[1],meanx))
pcaX <- prcomp(Xrep)
us <- pcaX$rotation
projX <- Xrep %*% us
barplot(pcaX$sdev)
summary(pcaX)
# Reduzindo para os dois primeiros eixos
plot(projX[,1],projX[,2],type='p',xlim=c(min(projX[,1]),max(projX[,1])),ylim=c(min(projX[,2]),max(projX[,2])),xlab='PCA1',ylab='PCA2',col='blue')
par(new=TRUE)
plot(projX[which(Y==1),1],projX[which(Y==1),2],type='p',xlim=c(min(projX[,1]),max(projX[,1])),ylim=c(min(projX[,2]),max(projX[,2])),
col='red',xlab='PCA1',ylab='PCA2',
sub='Projeção das classes em PCA1 e PCA2')
# Comparacao: reduzindo aos eixos 4 e 5
plot(projX[,4],projX[,5],type='p',xlim=c(min(projX[,4]),max(projX[,4])),ylim=c(min(projX[,5]),max(projX[,5])),xlab='PCA4',ylab='PCA5',col='blue')
par(new=TRUE)
plot(projX[which(Y==1),4],projX[which(Y==1),5],type='p',xlim=c(min(projX[,4]),max(projX[,4])),ylim=c(min(projX[,5]),max(projX[,5])),col='red',
xlab='PCA4',ylab='PCA5',
sub='Projeção das classes em PCA4 e PCA5')
###########################
# F-Score #
c1 <- X[which(Y==-1),]
c2 <- X[which(Y==1),]
n <- dim(X)[2]
f <- fscore(X,c1,c2,n)
print(f)
colnames(X[,order(f)])
###########################
# Kmeans #
k <- list()
for(i in 1:(nrow(t(X))-1))
{
h <- kmeans(t(X),i)
k[[i]] <- h$cluster
}
k
###########################
# Hierarchical clustering #
clusters <- hclust(dist(t(X)))
plot(clusters)
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- X[trainIndex,]
testData  <- X[-trainIndex,]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
setwd("~/Dropbox/Study/UFMG/Classes/ENG121/Prova/Solucao")
dim(pcaX)
dim(pcaX)
dim(projX)
dim(X)
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- X[trainIndex,]
testData  <- X[-trainIndex,]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
summary(svm.tune)
svm.tune
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- projX[trainIndex,]
testData  <- projX[-trainIndex,]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- projX[trainIndex,1:3]
testData  <- projX[-trainIndex,1:3]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- projX[trainIndex,1:4]
testData  <- projX[-trainIndex,1:4]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- projX[trainIndex,1:2]
testData  <- projX[-trainIndex,1:2]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune
levels <- unique(Y)
Y <- factor(Y, labels=make.names(levels))
trainIndex <- createDataPartition(bupa[,7],p=.7,list=FALSE)
trainData <- projX[trainIndex,]
testData  <- projX[-trainIndex,]
trainLabels <- Y[trainIndex]
testLabels <- Y[-trainIndex]
set.seed(1492)
ctrl <- trainControl(method="repeatedcv",
repeats=5,
summaryFunction=twoClassSummary,
classProbs=TRUE)
svm.tune <- train(x=trainData,
y=trainLabels,
method = "svmRadial",
tuneLength = 9,
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune
